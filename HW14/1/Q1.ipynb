{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3Hwf9bQzJUk"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from pandas import DataFrame\n",
    "import gensim.downloader as api\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiDy4ZsI5brA"
   },
   "outputs": [],
   "source": [
    "def show_DataFrame(dic, index):\n",
    "    return DataFrame(dic, index=index).applymap(lambda x: (x[0], round(x[1], 2))).T.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tyiM0wDs5eaQ"
   },
   "outputs": [],
   "source": [
    "def plot_scatter(prjected_words_vectors, words, colors):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.scatter(prjected_words_vectors[:,0], prjected_words_vectors[:,1], linewidths=2, color=colors)\n",
    "    for i, word in enumerate(words):\n",
    "        plt.annotate(word, xy=(prjected_words_vectors[i,0]-0.1, prjected_words_vectors[i,1]+0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwEM1ZFtgJgS"
   },
   "outputs": [],
   "source": [
    "wv_from_bin = api.load(\"glove-wiki-gigaword-200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6WI9A949YzU"
   },
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbD8IWa-d0wb"
   },
   "outputs": [],
   "source": [
    "words = ['', '', '', '', '', '', '', '', '', '']    # Question 1\n",
    "\n",
    "similar_words = dict()\n",
    "for word in words:\n",
    "    similar_words[word] = sorted(wv_from_bin.most_similar(word), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "show_DataFrame(similar_words, [f'Word {i + 1}' for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_aBBYqv9eJU"
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvhbkcbMkyJi"
   },
   "outputs": [],
   "source": [
    "words_groups = [['',        '',         '' ],       # Question 2\n",
    "                ['',        '',         '' ],\n",
    "                ['',        '',         '' ],\n",
    "                ['',        '',         '' ],\n",
    "                ['',        '',         '' ]]\n",
    "\n",
    "\n",
    "distances = dict()\n",
    "for w1, w2, w3 in words_groups:\n",
    "    distances[w1] = [(w2, wv_from_bin.distance(w1, w2)), (w3, wv_from_bin.distance(w1, w3))]\n",
    "\n",
    "show_DataFrame(distances, ['Near Word', 'Far Word'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjvW-iQg9kw9"
   },
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0flZ8urpukH"
   },
   "outputs": [],
   "source": [
    "words_groups = [['king',        'woman',    'man' ],\n",
    "                ['actor',       'girl',     'boy' ],\n",
    "                ['doctor',      'she',      'he'  ],\n",
    "                ['homemaker',   'she',      'he'  ],\n",
    "                ['football',    'woman',    'man' ]]\n",
    "\n",
    "\n",
    "first_distances = dict()\n",
    "second_distances = dict()\n",
    "for w1, w2, w3 in words_groups:\n",
    "    first_distances[str((str(w1), w2, w3))] = sorted(wv_from_bin.most_similar(positive=[w1, w2], negative=[w3]), key=lambda item: item[1], reverse=True)\n",
    "    second_distances[str((w1, w2, w3))] = sorted(wv_from_bin.most_similar(positive=[w1, w3], negative=[w2]), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AqKyp1Zsh4u"
   },
   "outputs": [],
   "source": [
    "show_DataFrame(first_distances, [f'Word {i + 1}' for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFHCo0MasmRk"
   },
   "outputs": [],
   "source": [
    "show_DataFrame(second_distances, [f'Word {i + 1}' for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnFQRGMx-lrP"
   },
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEyrxlw7yox2"
   },
   "outputs": [],
   "source": [
    "words = ['woman', 'man', 'king', 'queen', 'boy', 'girl', 'actor', 'actress', 'king', 'queen']\n",
    "words_vectors = [wv_from_bin.get_vector(word) for word in words]\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "prjected_words_vectors = pca.fit_transform(words_vectors)\n",
    "\n",
    "plot_scatter(prjected_words_vectors, words, 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ocdkNbb-uW4"
   },
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJ2Dwyu2-vb4"
   },
   "outputs": [],
   "source": [
    "# Question 5\n",
    "words = ['', '', '', '', '', '', '', '', '', '']\n",
    "words_vectors = [wv_from_bin.get_vector(word) for word in words]\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "prjected_words_vectors = pca.fit_transform(words_vectors)\n",
    "\n",
    "plot_scatter(prjected_words_vectors, words, 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jx77MZYw-SyZ"
   },
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXCFh6wStZCM"
   },
   "outputs": [],
   "source": [
    "words_group1 = ['cat', 'dog', 'mouse', 'cow', 'lion']\n",
    "words_group2 = ['iran', 'iraq', 'qatar', 'emirates', 'afghanistan']\n",
    "words_group3 = ['green', 'blue', 'red', 'white', 'black']\n",
    "\n",
    "words_group1_vectors = [wv_from_bin.get_vector(word) for word in words_group1]\n",
    "words_group2_vectors = [wv_from_bin.get_vector(word) for word in words_group2]\n",
    "words_group3_vectors = [wv_from_bin.get_vector(word) for word in words_group3]\n",
    "\n",
    "words = np.array(words_group1 + words_group2 + words_group3)\n",
    "colors = ['green']*len(words_group1) + ['blue']*len(words_group2) + ['red']*len(words_group3)\n",
    "words_vectors = np.array(words_group1_vectors + words_group2_vectors + words_group3_vectors)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "prjected_words_vectors = pca.fit_transform(words_vectors)\n",
    "\n",
    "plot_scatter(prjected_words_vectors, words, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MDzZBii-ywx"
   },
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIj66cX--rRm"
   },
   "outputs": [],
   "source": [
    "# Question 7\n",
    "words_group1 = ['', '', '', '', '']\n",
    "words_group2 = ['', '', '', '', '']\n",
    "words_group3 = ['', '', '', '', '']\n",
    "\n",
    "words_group1_vectors = [wv_from_bin.get_vector(word) for word in words_group1]\n",
    "words_group2_vectors = [wv_from_bin.get_vector(word) for word in words_group2]\n",
    "words_group3_vectors = [wv_from_bin.get_vector(word) for word in words_group3]\n",
    "\n",
    "words = np.array(words_group1 + words_group2 + words_group3)\n",
    "colors = ['green']*len(words_group1) + ['blue']*len(words_group2) + ['red']*len(words_group3)\n",
    "words_vectors = np.array(words_group1_vectors + words_group2_vectors + words_group3_vectors)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "prjected_words_vectors = pca.fit_transform(words_vectors)\n",
    "\n",
    "plot_scatter(prjected_words_vectors, words, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ7IqQfw9_pO"
   },
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "po-LERr-0bOe"
   },
   "outputs": [],
   "source": [
    "many_dict = dict()\n",
    "many_dict[str(('many', 'cow', 'one'))] = wv_from_bin.most_similar(positive=['many', 'cow'], negative=['one'])\n",
    "show_DataFrame(many_dict, [f'Word {i + 1}' for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68eCDQ_Gsc5w"
   },
   "outputs": [],
   "source": [
    "many_dict = dict()\n",
    "many_dict[str(('young', 'cow', 'old'))] = wv_from_bin.most_similar(positive=['young', 'cow'], negative=['old'])\n",
    "show_DataFrame(many_dict, [f'Word {i + 1}' for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0EO7onxs39f"
   },
   "outputs": [],
   "source": [
    "# Question 8\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Q1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
